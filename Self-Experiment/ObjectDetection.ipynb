{"cells":[{"cell_type":"markdown","metadata":{"id":"FJDDuZu5WFqJ"},"source":["# Download Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":49419,"status":"ok","timestamp":1700645497238,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"0TkN-AsbS9Mq","outputId":"7f38d80b-a82a-4d59-8162-9b73f50f156d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fiftyone\n","  Downloading fiftyone-0.22.3-py3-none-any.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from fiftyone)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Collecting argcomplete (from fiftyone)\n","  Downloading argcomplete-3.1.6-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.2)\n","Collecting boto3 (from fiftyone)\n","  Downloading boto3-1.29.5-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.2)\n","Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n","  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n","Collecting Deprecated (from fiftyone)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting ftfy (from fiftyone)\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n","Collecting hypercorn>=0.13.2 (from fiftyone)\n","  Downloading hypercorn-0.15.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n","Collecting kaleido!=0.2.1.post1 (from fiftyone)\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n","Collecting mongoengine==0.24.2 (from fiftyone)\n","  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n","  Downloading motor-3.3.2-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n","Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n","Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n","Collecting pprintpp (from fiftyone)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n","Collecting pymongo>=3.12 (from fiftyone)\n","  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.3.post1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.6.3)\n","Collecting retrying (from fiftyone)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n","Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n","  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n","Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n","  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n","Collecting starlette>=0.24.0 (from fiftyone)\n","  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n","  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n","Collecting xmltodict (from fiftyone)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n","  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n","Collecting fiftyone-brain~=0.13.2 (from fiftyone)\n","  Downloading fiftyone_brain-0.13.3-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fiftyone-db~=0.4 (from fiftyone)\n","  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting voxel51-eta~=0.12 (from fiftyone)\n","  Downloading voxel51_eta-0.12.0-py2.py3-none-any.whl (570 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.0/570.0 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.8.1.78)\n","Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n","Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain~=0.13.2->fiftyone) (1.11.3)\n","Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n","  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n","Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n","  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n","Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.3)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n","Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from voxel51-eta~=0.12->fiftyone)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.18.3)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.7)\n","Collecting jsonlines (from voxel51-eta~=0.12->fiftyone)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Collecting py7zr (from voxel51-eta~=0.12->fiftyone)\n","  Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rarfile (from voxel51-eta~=0.12->fiftyone)\n","  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (1.16.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.4.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (5.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.0.7)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n","Collecting botocore<1.33.0,>=1.32.5 (from boto3->fiftyone)\n","  Downloading botocore-1.32.5-py3-none-any.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->fiftyone)\n","  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n","Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->fiftyone)\n","  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.2.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.2.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.1.3)\n","Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2023.7.22)\n","Collecting httpcore (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta~=0.12->fiftyone) (23.1.0)\n","Collecting texttable (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta~=0.12->fiftyone) (3.3.2)\n","Installing collected packages: wcwidth, texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n","  Attempting uninstall: wcwidth\n","    Found existing installation: wcwidth 0.2.10\n","    Uninstalling wcwidth-0.2.10:\n","      Successfully uninstalled wcwidth-0.2.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Deprecated-1.2.14 aiofiles-23.2.1 argcomplete-3.1.6 boto3-1.29.5 botocore-1.32.5 brotli-1.1.0 dacite-1.7.0 dill-0.3.7 dnspython-2.4.2 fiftyone-0.22.3 fiftyone-brain-0.13.3 fiftyone-db-0.4.0 ftfy-6.1.3 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.2 httpx-0.25.1 hypercorn-0.15.0 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.3.2 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.19.0 pymongo-4.6.0 pyppmd-1.1.0 pyzstd-0.15.9 rarfile-4.1 retrying-1.3.4 s3transfer-0.7.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.32.0.post1 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.0 wcwidth-0.2.12 wsproto-1.2.0 xmltodict-0.13.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["wcwidth"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Collecting fiftyone-db-ubuntu2204\n","  Downloading fiftyone_db_ubuntu2204-0.4.0-py3-none-manylinux1_x86_64.whl (42.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fiftyone-db-ubuntu2204\n","Successfully installed fiftyone-db-ubuntu2204-0.4.0\n"]}],"source":["!pip install fiftyone\n","!pip install fiftyone-db-ubuntu2204"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15148,"status":"ok","timestamp":1700645512380,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"2iz19RHaTULp","outputId":"2970d332-3a05-46be-d833-999d97bdd325"},"outputs":[{"name":"stdout","output_type":"stream","text":["Migrating database to v0.22.3\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.migrations.runner:Migrating database to v0.22.3\n"]}],"source":["import fiftyone as fo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1700645512381,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"0U0P22CsTqbG","outputId":"cb69b87b-1a85-48ba-edbc-fdfd65775f5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Versi FiftyOne: 0.22.3\n"]}],"source":["print(\"Versi FiftyOne:\", fo.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGd-CXvujzQm"},"outputs":[],"source":["import fiftyone.zoo as foz"]},{"cell_type":"markdown","metadata":{"id":"jp9xNHLnT7wS"},"source":["## Dataset Info\n","Dataset: [COCO-2017](https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#dataset-zoo-coco-2017)\n","\n","COCO defines 91 classes but the data only uses 80 classes\n","\n","Full split stats:\n","- Total Train split: 118,287 images\n","- Total Test split: 40,670 images\n","- Total Validation split: 5,000 images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":561186,"status":"ok","timestamp":1700646073555,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"dnY2f0U8T5Ag","outputId":"3bc0b4c4-7dfe-4e41-ccc6-a6c56be30811"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"name":"stdout","output_type":"stream","text":["Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████|    1.9Gb/1.9Gb [2.5s elapsed, 0s remaining, 759.7Mb/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [2.5s elapsed, 0s remaining, 759.7Mb/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"name":"stdout","output_type":"stream","text":["Downloading 3000 images\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading 3000 images\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |████████████████| 3000/3000 [4.8m elapsed, 0s remaining, 11.0 images/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |████████████████| 3000/3000 [4.8m elapsed, 0s remaining, 11.0 images/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stdout","output_type":"stream","text":["Loading 'coco-2017' split 'train'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |███████████████| 3000/3000 [33.9s elapsed, 0s remaining, 74.1 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |███████████████| 3000/3000 [33.9s elapsed, 0s remaining, 74.1 samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Dataset 'coco-2017-train-3000' created\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train-3000' created\n"]},{"name":"stdout","output_type":"stream","text":["Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"name":"stdout","output_type":"stream","text":["Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"name":"stdout","output_type":"stream","text":["Downloading 1000 images\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading 1000 images\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |████████████████| 1000/1000 [1.7m elapsed, 0s remaining, 10.1 images/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |████████████████| 1000/1000 [1.7m elapsed, 0s remaining, 10.1 images/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Writing annotations for 1000 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Writing annotations for 1000 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stdout","output_type":"stream","text":["Loading 'coco-2017' split 'validation'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |███████████████| 1000/1000 [9.9s elapsed, 0s remaining, 99.0 samples/s]       \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |███████████████| 1000/1000 [9.9s elapsed, 0s remaining, 99.0 samples/s]       \n"]},{"name":"stdout","output_type":"stream","text":["Dataset 'coco-2017-validation-1000' created\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation-1000' created\n"]},{"name":"stdout","output_type":"stream","text":["Downloading split 'test' to '/root/fiftyone/coco-2017/test' if necessary\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Downloading split 'test' to '/root/fiftyone/coco-2017/test' if necessary\n"]},{"name":"stdout","output_type":"stream","text":["Test split is unlabeled; ignoring classes requirement\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:fiftyone.utils.coco:Test split is unlabeled; ignoring classes requirement\n"]},{"name":"stdout","output_type":"stream","text":["Downloading test info to '/root/fiftyone/coco-2017/tmp-download/image_info_test2017.zip'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading test info to '/root/fiftyone/coco-2017/tmp-download/image_info_test2017.zip'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████|    8.7Mb/8.7Mb [118.3ms elapsed, 0s remaining, 73.8Mb/s]     \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████|    8.7Mb/8.7Mb [118.3ms elapsed, 0s remaining, 73.8Mb/s]     \n"]},{"name":"stdout","output_type":"stream","text":["Extracting test info to '/root/fiftyone/coco-2017/raw/image_info_test2017.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Extracting test info to '/root/fiftyone/coco-2017/raw/image_info_test2017.json'\n"]},{"name":"stdout","output_type":"stream","text":["Downloading 500 images\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading 500 images\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████████████████| 500/500 [52.2s elapsed, 0s remaining, 10.1 images/s]     \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████████████████| 500/500 [52.2s elapsed, 0s remaining, 10.1 images/s]     \n"]},{"name":"stdout","output_type":"stream","text":["Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/test/labels.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/test/labels.json'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stdout","output_type":"stream","text":["Loading 'coco-2017' split 'test'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'test'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset is unlabeled; ignoring classes requirement\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:fiftyone.utils.coco:Dataset is unlabeled; ignoring classes requirement\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |█████████████████| 500/500 [237.6ms elapsed, 0s remaining, 2.2K samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████████| 500/500 [237.6ms elapsed, 0s remaining, 2.2K samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Dataset 'coco-2017-test-500' created\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-test-500' created\n"]}],"source":["#  Download Dataset from fiftyone\n","datasetTrain = foz.load_zoo_dataset(\"coco-2017\", split=\"train\", label_types=[\"detections\"], classes=[\"person\"], max_samples=3000)\n","datasetValid = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", label_types=[\"detections\"], classes=[\"person\"], max_samples=1000)\n","datasetTest = foz.load_zoo_dataset(\"coco-2017\", split=\"test\", label_types=[\"detections\"], classes=[\"person\"], max_samples=500)"]},{"cell_type":"markdown","metadata":{"id":"QnIVLHdCDEfh"},"source":["# Save Dataset to Drive\n","> Save the dataset to the drive so that it doesn't need to be downloaded again."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20500,"status":"ok","timestamp":1700656989754,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"XQNgATTDpeIH","outputId":"7c2e5072-975a-4612-9393-95fb07794634"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49556,"status":"ok","timestamp":1700622447155,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"NXjYedep-dXq","outputId":"0104e7c8-e257-46b1-8971-51ee6069ab88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory '/content/drive/My Drive/ObjectDetection/Dataset/Train' already exists; export will be merged with existing files\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:fiftyone.core.collections:Directory '/content/drive/My Drive/ObjectDetection/Dataset/Train' already exists; export will be merged with existing files\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |███████████████| 3000/3000 [48.9s elapsed, 0s remaining, 57.0 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |███████████████| 3000/3000 [48.9s elapsed, 0s remaining, 57.0 samples/s]      \n"]}],"source":["export_dir = \"/content/drive/My Drive/ObjectDetection/Dataset/Train\"\n","datasetTrain.export(export_dir=export_dir, dataset_type=fo.types.COCODetectionDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18738,"status":"ok","timestamp":1700622846832,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"hXvBz2uw1YE4","outputId":"be2d4511-5dbc-44ae-f1ff-ef3845f5a504"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory '/content/drive/My Drive/ObjectDetection/Dataset/Valid' already exists; export will be merged with existing files\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:fiftyone.core.collections:Directory '/content/drive/My Drive/ObjectDetection/Dataset/Valid' already exists; export will be merged with existing files\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |███████████████| 1000/1000 [17.9s elapsed, 0s remaining, 46.8 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |███████████████| 1000/1000 [17.9s elapsed, 0s remaining, 46.8 samples/s]      \n"]}],"source":["export_dir = \"/content/drive/My Drive/ObjectDetection/Dataset/Valid\"\n","datasetValid.export(export_dir=export_dir, dataset_type=fo.types.COCODetectionDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5293,"status":"ok","timestamp":1700623173884,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"yJqUTMY31Zhm","outputId":"0e746a1e-8f52-4957-ccbf-23748f4a01d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory '/content/drive/My Drive/ObjectDetection/Dataset/Test' already exists; export will be merged with existing files\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:fiftyone.core.collections:Directory '/content/drive/My Drive/ObjectDetection/Dataset/Test' already exists; export will be merged with existing files\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |█████████████████| 500/500 [5.2s elapsed, 0s remaining, 88.2 samples/s]       \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████████| 500/500 [5.2s elapsed, 0s remaining, 88.2 samples/s]       \n"]}],"source":["export_dir = \"/content/drive/My Drive/ObjectDetection/Dataset/Test\"\n","datasetTest.export(export_dir=export_dir, dataset_type=fo.types.COCODetectionDataset)"]},{"cell_type":"markdown","metadata":{"id":"uEZpFpdcWbiY"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_5m4e1NUgDm"},"outputs":[],"source":["import os\n","import cv2\n","import json\n","import matplotlib.pyplot as plt\n","import albumentations as A"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28805,"status":"ok","timestamp":1701364238084,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"lRe_AzBROrmz","outputId":"2cdea6ca-4731-49a8-eddd-3a43f71414ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"JeorB9NfWgUr"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLKznqoeVUn5"},"outputs":[],"source":["# Get Dataset Path from Drive\n","def getDatasetPath(typeSplit):\n","  label_path = f'/content/drive/My Drive/ObjectDetection/Dataset/{typeSplit}/labels.json'\n","  image_general_path = f'/content/drive/My Drive/ObjectDetection/Dataset/{typeSplit}/data/'\n","  return label_path, image_general_path\n","\n","# Dataset Path Initialization\n","labels_train, image_train = getDatasetPath('Train')\n","labels_valid, image_valid = getDatasetPath('Valid')\n","labels_test, image_test = getDatasetPath('Test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHBMeZbDaCwN"},"outputs":[],"source":["def loadDataset(labels_path, image_general_path):\n","  # load file .json\n","  with open(labels_path, 'r') as file:\n","    labels = json.load(file)\n","\n","  # Get .json file for categories and image_paths\n","  categories = {category['id']: category['name'] for category in labels['categories']}\n","  image_paths = {image['id']: image_general_path + image['file_name'] for image in labels['images']}\n","\n","  # load image\n","  data = []\n","  for image_id, image_path in image_paths.items():\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Load label and bbox\n","    bbox = []\n","    label = []\n","    for annotation in labels['annotations']:\n","      if annotation['image_id'] == image_id:\n","        category_id = annotation['category_id']\n","        label.append(categories[category_id])\n","        bbox.append(list(map(int, annotation['bbox'])))\n","\n","    # append image, bbox, label to data\n","    data.append({'image': image, 'bbox': bbox, 'label': label})\n","\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTnBabtUxD17"},"outputs":[],"source":["def showDataset(dataset, num=5):\n","    for i in range(min(num, len(dataset))):\n","        entry = dataset[i]\n","        image = entry['image']\n","        bboxes = entry['bbox']\n","        labels = entry['label']\n","\n","        # show image with bbox and label\n","        fig, axes = plt.subplots(1, figsize=(8, 8))\n","        axes.imshow(image)\n","\n","        for bbox, label in zip(bboxes, labels):\n","            x, y, w, h = map(int, bbox)\n","            rect = plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='g', facecolor='none')\n","            axes.add_patch(rect)\n","            axes.text(x, y, label, color='r', verticalalignment='top')\n","\n","        axes.axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Mic9c0OGoJvEThjmhMGvLOGyUSAx25He"},"executionInfo":{"elapsed":1493186,"status":"ok","timestamp":1701329105666,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"AXdRjoEXjqk5","outputId":"e5066ba4-26b3-4d55-fe2d-b7f60d111187"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Load Train Dataset\n","trainDataset = loadDataset(labels_train, image_train)\n","showDataset(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1iVpzAbAT0ONkjooPBpo2ePQ6vJma8Xtb"},"executionInfo":{"elapsed":468314,"status":"ok","timestamp":1701329573975,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"FQvvjzqE_Cu4","outputId":"fc29a4e5-272e-4ff5-bfdd-0e9271ce26c2"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Load Valid Dataset\n","validDataset = loadDataset(labels_valid, image_valid)\n","showDataset(validDataset)"]},{"cell_type":"markdown","metadata":{"id":"FSZQ9o2DCt1u"},"source":["# Dataset Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Thw_10iyCriF"},"outputs":[],"source":["def resize_dataset(dataset, target_size=(416, 416)):\n","    for entry in dataset:\n","        image = entry['image']\n","        bboxes = entry['bbox']\n","\n","        # Get image dimensions\n","        original_height, original_width, _ = image.shape\n","\n","        # Calculate the scale change factor for width and height\n","        scale_x = target_size[0] / original_width\n","        scale_y = target_size[1] / original_height\n","\n","        # Resize image\n","        resized_image = cv2.resize(image, target_size)\n","\n","        # Normalize image\n","        # resized_image = resized_image / 255.0 # Consumes too many RAM resources\n","\n","        # Resize bboxes\n","        resized_bboxes = []\n","        for bbox in bboxes:\n","            resized_bbox = bbox.copy()\n","            resized_bbox[0] = int(bbox[0] * scale_x)\n","            resized_bbox[1] = int(bbox[1] * scale_y)\n","            resized_bbox[2] = int(bbox[2] * scale_x)\n","            resized_bbox[3] = int(bbox[3] * scale_y)\n","            resized_bboxes.append(resized_bbox)\n","\n","        # Update entry in the dataset\n","        entry['image'] = resized_image\n","        entry['bbox'] = resized_bboxes\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16td_btljvw6xb03790iUUVsuSnMmGlSr"},"executionInfo":{"elapsed":8523,"status":"ok","timestamp":1701329582490,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"2Z9QPo5URKHT","outputId":"f83f8824-b568-400e-99b2-c712b74fb578"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Resize Train Dataset\n","resize_dataset(trainDataset)\n","showDataset(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1v577aSZXD5BeMgy_rDE9dfPCr_OVeUPb"},"executionInfo":{"elapsed":2379,"status":"ok","timestamp":1701329584858,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"vJn5f4TDlMDN","outputId":"2a3b7b1a-551b-4315-cb6b-3ae51a66a0ee"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Resize Validation Dataset\n","resize_dataset(validDataset)\n","showDataset(validDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQn4xT-FPC-0"},"outputs":[],"source":["# Alternative normalization\n","def normalization(dataset):\n","  for entry in dataset:\n","    image = entry['image']\n","\n","    # Albumentations compose\n","    transform = A.Compose([\n","        A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0),\n","    ])\n","\n","    # Image normalization\n","    transformed = transform(image=image)\n","    normalized_image = transformed['image']\n","\n","    # Update entry in the dataset\n","    entry['image'] = normalized_image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1akmvLK97FQHIXhrJYS05eH5ZjP3X7-Hb"},"executionInfo":{"elapsed":8756,"status":"ok","timestamp":1701329593612,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"_TrXJJW7RD7Z","outputId":"c636e1da-7b8d-41eb-87d1-ac8135f505ea"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["normalization(trainDataset)\n","showDataset(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1teF-UG8EAh6bi7Z0WCDm9fgqG5Cxr-D7"},"executionInfo":{"elapsed":5419,"status":"ok","timestamp":1701329599015,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"QXgfWjLPUqcO","outputId":"77b75826-c6de-4393-b1a2-d53f24f828a2"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["normalization(validDataset)\n","showDataset(validDataset)"]},{"cell_type":"markdown","metadata":{"id":"4Njlqr8uD2se"},"source":["# Data Structuring\n","> This data structuring is used to rearrange datasets to meet the requirements of Ultralytics"]},{"cell_type":"markdown","metadata":{"id":"fC3TKmDweZB4"},"source":["## Labeling categories"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1701356225465,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"pQZhYHZhmsUG","outputId":"c871b29b-daf9-410b-8636-87867e2eaa29"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'airplane', 1: 'apple', 2: 'backpack', 3: 'banana', 4: 'baseball bat', 5: 'baseball glove', 6: 'bear', 7: 'bed', 8: 'bench', 9: 'bicycle', 10: 'bird', 11: 'boat', 12: 'book', 13: 'bottle', 14: 'bowl', 15: 'broccoli', 16: 'bus', 17: 'cake', 18: 'car', 19: 'carrot', 20: 'cat', 21: 'cell phone', 22: 'chair', 23: 'clock', 24: 'couch', 25: 'cow', 26: 'cup', 27: 'dining table', 28: 'dog', 29: 'donut', 30: 'elephant', 31: 'fire hydrant', 32: 'fork', 33: 'frisbee', 34: 'giraffe', 35: 'hair drier', 36: 'handbag', 37: 'horse', 38: 'hot dog', 39: 'keyboard', 40: 'kite', 41: 'knife', 42: 'laptop', 43: 'microwave', 44: 'motorcycle', 45: 'mouse', 46: 'orange', 47: 'oven', 48: 'parking meter', 49: 'person', 50: 'pizza', 51: 'potted plant', 52: 'refrigerator', 53: 'remote', 54: 'sandwich', 55: 'scissors', 56: 'sheep', 57: 'sink', 58: 'skateboard', 59: 'skis', 60: 'snowboard', 61: 'spoon', 62: 'sports ball', 63: 'stop sign', 64: 'suitcase', 65: 'surfboard', 66: 'teddy bear', 67: 'tennis racket', 68: 'tie', 69: 'toaster', 70: 'toilet', 71: 'toothbrush', 72: 'traffic light', 73: 'train', 74: 'truck', 75: 'tv', 76: 'umbrella', 77: 'vase', 78: 'wine glass', 79: 'zebra'}\n"]}],"source":["# Load file .json\n","labels_path= '/content/drive/My Drive/ObjectDetection/Dataset/Train/labels.json'\n","with open(labels_path, 'r') as file:\n","    labels = json.load(file)\n","\n","# Get .json file for categories | see the class in anotation\n","categories = {category['id']: category['name'] for category in labels['categories']}\n","print(categories)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHto6thv9ZIO"},"outputs":[],"source":["# index labeling\n","label_to_index = {\n","    'airplane': 0, 'apple': 1, 'backpack': 2, 'banana': 3, 'baseball bat': 4,\n","    'baseball glove': 5, 'bear': 6, 'bed': 7, 'bench': 8, 'bicycle': 9,\n","    'bird': 10, 'boat': 11, 'book': 12, 'bottle': 13, 'bowl': 14,\n","    'broccoli': 15, 'bus': 16, 'cake': 17, 'car': 18, 'carrot': 19,\n","    'cat': 20, 'cell phone': 21, 'chair': 22, 'clock': 23, 'couch': 24,\n","    'cow': 25, 'cup': 26, 'dining table': 27, 'dog': 28, 'donut': 29,\n","    'elephant': 30, 'fire hydrant': 31, 'fork': 32, 'frisbee': 33,\n","    'giraffe': 34, 'hair drier': 35, 'handbag': 36, 'horse': 37,\n","    'hot dog': 38, 'keyboard': 39, 'kite': 40, 'knife': 41, 'laptop': 42,\n","    'microwave': 43, 'motorcycle': 44, 'mouse': 45, 'orange': 46,\n","    'oven': 47, 'parking meter': 48, 'person': 49, 'pizza': 50,\n","    'potted plant': 51, 'refrigerator': 52, 'remote': 53, 'sandwich': 54,\n","    'scissors': 55, 'sheep': 56, 'sink': 57, 'skateboard': 58, 'skis': 59,\n","    'snowboard': 60, 'spoon': 61, 'sports ball': 62, 'stop sign': 63,\n","    'suitcase': 64, 'surfboard': 65, 'teddy bear': 66, 'tennis racket': 67,\n","    'tie': 68, 'toaster': 69, 'toilet': 70, 'toothbrush': 71,\n","    'traffic light': 72, 'train': 73, 'truck': 74, 'tv': 75, 'umbrella': 76,\n","    'vase': 77, 'wine glass': 78, 'zebra': 79\n","}"]},{"cell_type":"markdown","metadata":{"id":"vVblwjn_eVzb"},"source":["# Structuring data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01AToQmbNJOv"},"outputs":[],"source":["# This function for normalize bbox[0, 1]\n","def normalize_bbox(box, image_width, image_height):\n","    x_center, y_center, width, height = box\n","    x_center /= image_width\n","    y_center /= image_height\n","    width /= image_width\n","    height /= image_height\n","    return x_center, y_center, width, height"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkxWid8YUz-T"},"outputs":[],"source":["# This function is for structuring label indexing\n","def create_yolov5_structure(labels_path, image_general_path, output_path, split):\n","    # Load file .json\n","    with open(labels_path, 'r') as file:\n","        labels = json.load(file)\n","\n","    # Get .json file for categories and image_paths\n","    categories = {category['id']: category['name'] for category in labels['categories']}\n","    image_paths = {image['id']: image_general_path + image['file_name'] for image in labels['images']}\n","\n","    # Create YOLOv5 structure\n","    split_path = os.path.join(output_path, split)\n","    os.makedirs(os.path.join(split_path, 'images'), exist_ok=True)\n","    os.makedirs(os.path.join(split_path, 'labels'), exist_ok=True)\n","\n","    for image_id, image_path in image_paths.items():\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Load label and bbox\n","        bbox = []\n","        label = []\n","        for annotation in labels['annotations']:\n","            if annotation['image_id'] == image_id:\n","                category_id = annotation['category_id']\n","                label.append(categories[category_id])\n","                bbox.append(list(map(int, annotation['bbox'])))\n","\n","        # Save image\n","        image_filename = f\"{split}_{image_id}.jpg\"\n","        cv2.imwrite(os.path.join(split_path, 'images', image_filename), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","\n","        # Save label\n","        label_filename = f\"{split}_{image_id}.txt\"\n","        with open(os.path.join(split_path, 'labels', label_filename), 'w') as label_file:\n","            for idx, box in enumerate(bbox):\n","                label_name = label[idx]\n","                if label_name in label_to_index:\n","                    index = label_to_index[label_name]\n","                    normalized_box = normalize_bbox(box, image.shape[1], image.shape[0])\n","                    label_file.write(f\"{index} {' '.join(map(str, normalized_box))}\\n\")\n","                else:\n","                    print(f\"Warning: Label '{label_name}' not found!.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAl2D-9lU5j8"},"outputs":[],"source":["# Convert coco dataset valid\n","labels_path = '/content/drive/My Drive/ObjectDetection/Dataset/Valid/labels.json'\n","image_general_path = '/content/drive/My Drive/ObjectDetection/Dataset/Valid/data/'\n","output_path = '/content/drive/My Drive/ObjectDetection/Coco/'\n","\n","# Create YOLOv5 structure\n","create_yolov5_structure(labels_path, image_general_path, output_path, 'val')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHQnm65Fm-LN"},"outputs":[],"source":["# Convert coco dataset train\n","labels_path = '/content/drive/My Drive/ObjectDetection/Dataset/Train/labels.json'\n","image_general_path = '/content/drive/My Drive/ObjectDetection/Dataset/Train/data/'\n","output_path = '/content/drive/My Drive/ObjectDetection/Coco/'\n","\n","# Create YOLOv5 structure\n","create_yolov5_structure(labels_path, image_general_path, output_path, 'train')"]},{"cell_type":"markdown","metadata":{"id":"yzr5dgthqVn1"},"source":["# Data Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12936,"status":"ok","timestamp":1701364270800,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"xu4koCrLqzzp","outputId":"7856918b-048e-4158-e950-682d666b6656"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16078, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (21/21), done.\u001b[K\n","remote: Total 16078 (delta 6), reused 9 (delta 1), pack-reused 16056\u001b[K\n","Receiving objects: 100% (16078/16078), 14.64 MiB | 5.97 MiB/s, done.\n","Resolving deltas: 100% (11038/11038), done.\n","Collecting gitpython>=3.1.30 (from -r yolov5/requirements.txt (line 5))\n","  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n","Collecting Pillow>=10.0.1 (from -r yolov5/requirements.txt (line 9))\n","  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.3)\n","Collecting thop>=0.1.1 (from -r yolov5/requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.1.0+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n","Collecting ultralytics>=8.0.147 (from -r yolov5/requirements.txt (line 18))\n","  Downloading ultralytics-8.0.221-py3-none-any.whl (646 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m646.6/646.6 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, Pillow, gitdb, thop, gitpython, ultralytics\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 9.4.0\n","    Uninstalling Pillow-9.4.0:\n","      Successfully uninstalled Pillow-9.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pillow-10.1.0 gitdb-4.0.11 gitpython-3.1.40 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.221\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{},"output_type":"display_data"}],"source":["!git clone https://github.com/ultralytics/yolov5.git\n","!pip3 install -r yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701364278455,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"z_3FwnaRRTq3","outputId":"504c83b7-fe21-4d6a-d230-f6fb19365614"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34myolov5\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701346452206,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"YZgf8RvO0VOt","outputId":"a22acaac-266b-4834-eacb-bc81e9bae667"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["%cd content"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701346454794,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"qCDT8BDy1AWM","outputId":"6d1872ff-fc82-4a04-fff2-37dc390b4e0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34myolov5\u001b[0m/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1701364284115,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"vkchBGHF1D5p","outputId":"ed8fd73f-6306-4622-db52-f4bc31d16ada"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n"]}],"source":["%cd yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3311262,"status":"ok","timestamp":1701371864268,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"e1m4fwl9zj9t","outputId":"3e512a6b-b7dc-4cfa-d551-3e167a5f1432"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-11-30 17:11:39.933301: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-30 17:11:39.933355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-30 17:11:39.933403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=/content/drive/MyDrive/ObjectDetection/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-247-g3f02fde Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 11.9MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 129MB/s] \n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n","\n","Transferred 348/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/ObjectDetection/Coco/train/labels.cache... 3000 images, 0 backgrounds, 0 corrupt: 100% 3000/3000 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/My Drive/ObjectDetection/Coco/train/images/train_2136.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/ObjectDetection/Coco/val/labels.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% 1000/1000 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.43 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49      6.84G    0.09396     0.1023     0.1017        325        640: 100% 94/94 [02:16<00:00,  1.45s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [02:48<00:00, 10.51s/it]\n","                   all       1000       9722      0.434     0.0238    0.00673    0.00168\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49      9.62G    0.08069    0.09206    0.05176        334        640: 100% 94/94 [02:06<00:00,  1.34s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:21<00:00,  1.34s/it]\n","                   all       1000       9722      0.496      0.115      0.065     0.0203\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49      9.62G    0.07745    0.09233    0.03905        341        640: 100% 94/94 [02:07<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:20<00:00,  1.25s/it]\n","                   all       1000       9722      0.459      0.131     0.0858     0.0284\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49      9.62G     0.0754    0.09257    0.03646        429        640: 100% 94/94 [02:10<00:00,  1.39s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:22<00:00,  1.40s/it]\n","                   all       1000       9722      0.414       0.14     0.0906     0.0336\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49      9.62G    0.07441    0.09332    0.03461        305        640: 100% 94/94 [02:10<00:00,  1.39s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:21<00:00,  1.36s/it]\n","                   all       1000       9722      0.343      0.146      0.106     0.0392\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49      9.62G     0.0737    0.09468    0.03395        393        640: 100% 94/94 [02:07<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.20s/it]\n","                   all       1000       9722      0.245       0.15     0.0685     0.0232\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49      9.62G    0.07238    0.09328    0.03168        323        640: 100% 94/94 [02:06<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.23s/it]\n","                   all       1000       9722      0.289      0.141     0.0912      0.036\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49      9.62G    0.07178    0.09429    0.03058        342        640: 100% 94/94 [02:08<00:00,  1.37s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.21s/it]\n","                   all       1000       9722      0.255      0.158     0.0801     0.0291\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49      9.62G     0.0708    0.09383    0.02932        492        640: 100% 94/94 [02:05<00:00,  1.34s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.18s/it]\n","                   all       1000       9722      0.286      0.167      0.107     0.0422\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49      9.62G    0.07037    0.09374    0.02848        413        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.22s/it]\n","                   all       1000       9722      0.266      0.163      0.105     0.0421\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49      9.62G    0.06964    0.09231    0.02745        302        640: 100% 94/94 [02:06<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:20<00:00,  1.25s/it]\n","                   all       1000       9722       0.36      0.162      0.125     0.0456\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49      9.62G    0.06888     0.0924    0.02684        353        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.22s/it]\n","                   all       1000       9722      0.309      0.168      0.118     0.0479\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49      9.62G    0.06869    0.09366    0.02621        364        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.15s/it]\n","                   all       1000       9722       0.32      0.182      0.139      0.053\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49      9.62G    0.06814    0.09321    0.02573        291        640: 100% 94/94 [02:04<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:21<00:00,  1.34s/it]\n","                   all       1000       9722      0.308      0.165      0.109     0.0413\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49      9.62G    0.06782    0.09216    0.02546        370        640: 100% 94/94 [02:04<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.18s/it]\n","                   all       1000       9722      0.312      0.166      0.115     0.0455\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49      9.62G    0.06764    0.09274     0.0244        423        640: 100% 94/94 [02:03<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.11s/it]\n","                   all       1000       9722      0.261      0.182      0.114      0.046\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49      9.62G    0.06675     0.0919    0.02395        394        640: 100% 94/94 [02:04<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.16s/it]\n","                   all       1000       9722      0.363      0.178       0.14     0.0595\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49      9.62G    0.06685    0.09187    0.02344        427        640: 100% 94/94 [02:04<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:20<00:00,  1.29s/it]\n","                   all       1000       9722      0.275      0.181      0.119     0.0472\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49      9.62G    0.06646     0.0929    0.02324        459        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.19s/it]\n","                   all       1000       9722      0.303      0.188       0.13     0.0539\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49      9.62G     0.0664    0.09301    0.02301        339        640: 100% 94/94 [02:06<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.17s/it]\n","                   all       1000       9722      0.273      0.176      0.109      0.044\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49      9.62G     0.0658    0.09243    0.02274        424        640: 100% 94/94 [02:08<00:00,  1.36s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.23s/it]\n","                   all       1000       9722        0.2      0.189      0.109     0.0441\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49      9.62G    0.06559    0.09294    0.02172        434        640: 100% 94/94 [02:05<00:00,  1.34s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.12s/it]\n","                   all       1000       9722      0.291      0.194      0.132     0.0548\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49      9.62G    0.06505    0.09061    0.02195        394        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.16s/it]\n","                   all       1000       9722      0.281      0.185      0.136     0.0579\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49      9.62G     0.0646    0.09146     0.0209        413        640: 100% 94/94 [02:05<00:00,  1.34s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.21s/it]\n","                   all       1000       9722      0.316      0.185      0.122     0.0481\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49      9.62G     0.0644    0.08983    0.02101        364        640: 100% 94/94 [02:06<00:00,  1.35s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.12s/it]\n","                   all       1000       9722      0.294      0.183      0.136     0.0589\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49      9.62G    0.06377    0.08962    0.02047        388        640: 100% 94/94 [02:04<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.15s/it]\n","                   all       1000       9722      0.287      0.183      0.136     0.0576\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49      9.62G    0.06368    0.09325    0.02052        408        640: 100% 94/94 [02:04<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.17s/it]\n","                   all       1000       9722      0.305      0.183      0.142     0.0608\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49      9.62G     0.0634    0.08891    0.01973        378        640: 100% 94/94 [02:04<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.07s/it]\n","                   all       1000       9722      0.304      0.195      0.138     0.0589\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49      9.62G    0.06309    0.08962    0.01932        347        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.12s/it]\n","                   all       1000       9722      0.277      0.187      0.129      0.054\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49      9.62G    0.06311    0.09018    0.01951        326        640: 100% 94/94 [02:01<00:00,  1.29s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.14s/it]\n","                   all       1000       9722      0.337      0.189      0.156     0.0692\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49      9.62G    0.06273    0.08935     0.0192        312        640: 100% 94/94 [02:00<00:00,  1.29s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:19<00:00,  1.19s/it]\n","                   all       1000       9722      0.282      0.192      0.128     0.0539\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49      9.62G    0.06202    0.08747    0.01862        372        640: 100% 94/94 [02:01<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.07s/it]\n","                   all       1000       9722      0.263      0.196       0.12     0.0505\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49      9.62G    0.06179    0.08709    0.01856        313        640: 100% 94/94 [02:02<00:00,  1.31s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.08s/it]\n","                   all       1000       9722      0.253      0.203      0.137     0.0588\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/49      9.62G    0.06167    0.08937     0.0181        421        640: 100% 94/94 [02:01<00:00,  1.29s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.13s/it]\n","                   all       1000       9722      0.278      0.203      0.134     0.0587\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/49      9.62G    0.06137    0.08758    0.01771        393        640: 100% 94/94 [02:01<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.14s/it]\n","                   all       1000       9722      0.252      0.197      0.133     0.0589\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/49      9.62G    0.06088     0.0874    0.01774        343        640: 100% 94/94 [02:01<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.10s/it]\n","                   all       1000       9722      0.296      0.176      0.134     0.0588\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/49      9.62G    0.06099    0.08735    0.01748        380        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.10s/it]\n","                   all       1000       9722      0.275      0.195       0.14     0.0632\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/49      9.62G    0.06072    0.08709    0.01738        385        640: 100% 94/94 [02:02<00:00,  1.31s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.10s/it]\n","                   all       1000       9722      0.241      0.185      0.122     0.0518\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/49      9.62G    0.06035    0.08886     0.0167        394        640: 100% 94/94 [02:04<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.11s/it]\n","                   all       1000       9722      0.265      0.186       0.13     0.0559\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/49      9.62G    0.06007    0.08782    0.01679        297        640: 100% 94/94 [02:01<00:00,  1.29s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.17s/it]\n","                   all       1000       9722      0.284      0.194      0.135     0.0599\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/49      9.62G    0.05997    0.08694    0.01661        327        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.19s/it]\n","                   all       1000       9722      0.263      0.192      0.136     0.0596\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/49      9.62G    0.05968    0.08633    0.01657        443        640: 100% 94/94 [02:02<00:00,  1.31s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.10s/it]\n","                   all       1000       9722      0.266      0.184      0.139     0.0627\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/49      9.62G    0.05944     0.0872    0.01621        365        640: 100% 94/94 [02:05<00:00,  1.33s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.13s/it]\n","                   all       1000       9722      0.248      0.204      0.133     0.0595\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/49      9.62G    0.05914    0.08573    0.01638        470        640: 100% 94/94 [02:05<00:00,  1.34s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.10s/it]\n","                   all       1000       9722      0.221       0.18      0.122     0.0553\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/49      9.62G    0.05865    0.08491    0.01595        450        640: 100% 94/94 [02:03<00:00,  1.31s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.08s/it]\n","                   all       1000       9722      0.242      0.196      0.126     0.0562\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/49      9.62G     0.0588    0.08492    0.01567        301        640: 100% 94/94 [02:03<00:00,  1.32s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.07s/it]\n","                   all       1000       9722      0.255      0.188      0.137     0.0625\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/49      9.62G    0.05842    0.08485    0.01558        499        640: 100% 94/94 [02:01<00:00,  1.29s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.14s/it]\n","                   all       1000       9722      0.251      0.189       0.13     0.0596\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/49      9.62G    0.05855    0.08547    0.01537        331        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.16s/it]\n","                   all       1000       9722      0.236      0.181      0.123     0.0568\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/49      9.62G    0.05823    0.08494    0.01541        536        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:16<00:00,  1.06s/it]\n","                   all       1000       9722      0.243      0.202      0.129      0.059\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/49      9.62G    0.05784    0.08417    0.01533        433        640: 100% 94/94 [02:02<00:00,  1.30s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:17<00:00,  1.09s/it]\n","                   all       1000       9722      0.258      0.188      0.127     0.0569\n","\n","50 epochs completed in 2.047 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 14.8MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 14.8MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:18<00:00,  1.17s/it]\n","                   all       1000       9722      0.338      0.189      0.156     0.0692\n","              airplane       1000         20      0.468        0.3      0.319      0.166\n","                 apple       1000         31          0          0     0.0192       0.01\n","              backpack       1000        155     0.0949     0.0323     0.0204    0.00823\n","                banana       1000         49          0          0     0.0301    0.00937\n","          baseball bat       1000         48      0.267      0.205     0.0946     0.0371\n","        baseball glove       1000         57      0.255      0.253      0.161     0.0892\n","                   bed       1000         18       0.67     0.0556     0.0925     0.0303\n","                 bench       1000        111      0.182     0.0991     0.0619     0.0199\n","               bicycle       1000        102      0.271      0.235      0.144     0.0472\n","                  bird       1000         80       0.28      0.025     0.0327     0.0227\n","                  boat       1000         96      0.184      0.104     0.0722     0.0263\n","                  book       1000        101       0.18     0.0326     0.0309     0.0103\n","                bottle       1000        252      0.281      0.254      0.144     0.0518\n","                  bowl       1000        101      0.371      0.238      0.205     0.0982\n","              broccoli       1000          5          1          0     0.0118    0.00241\n","                   bus       1000         78      0.436      0.385      0.342      0.175\n","                  cake       1000         54      0.265       0.22      0.121     0.0434\n","                   car       1000        464      0.286      0.369      0.219     0.0849\n","                carrot       1000         21       0.48     0.0457     0.0437    0.00949\n","                   cat       1000          8       0.41      0.125      0.107     0.0536\n","            cell phone       1000         81      0.213     0.0635     0.0835     0.0398\n","                 chair       1000        504      0.197      0.141     0.0876     0.0302\n","                 clock       1000         39      0.363      0.513      0.319      0.165\n","                 couch       1000         47      0.235     0.0213     0.0835     0.0377\n","                   cow       1000         27      0.119      0.222      0.232      0.108\n","                   cup       1000        228      0.283       0.32      0.196     0.0922\n","          dining table       1000        170      0.222     0.0294     0.0262    0.00819\n","                   dog       1000         36      0.446      0.194      0.222      0.146\n","                 donut       1000         30      0.519      0.533        0.5      0.214\n","              elephant       1000         38      0.256        0.5      0.355      0.145\n","          fire hydrant       1000         21      0.449      0.381      0.322       0.19\n","                  fork       1000         35     0.0983     0.0286     0.0677     0.0299\n","               frisbee       1000         32      0.487        0.5      0.424      0.212\n","               giraffe       1000         10      0.683        0.2      0.232     0.0818\n","               handbag       1000        195      0.104     0.0154     0.0207    0.00792\n","                 horse       1000         70      0.416      0.371      0.297      0.122\n","               hot dog       1000         39      0.615     0.0256     0.0795     0.0391\n","              keyboard       1000         18      0.335      0.167       0.17     0.0617\n","                  kite       1000        111      0.259      0.324      0.175     0.0765\n","                 knife       1000         60          0          0     0.0158    0.00446\n","                laptop       1000         30      0.409        0.5      0.267      0.121\n","             microwave       1000          4          0          0     0.0108    0.00716\n","            motorcycle       1000        121      0.334       0.38      0.247     0.0791\n","                 mouse       1000          7      0.164      0.286       0.33      0.171\n","                orange       1000         21      0.121     0.0476     0.0476     0.0239\n","                  oven       1000         18          0          0     0.0252    0.00448\n","         parking meter       1000          7          1          0      0.149     0.0891\n","                person       1000       4308      0.367      0.554      0.379      0.156\n","                 pizza       1000         89      0.442       0.27      0.236      0.121\n","          potted plant       1000         42      0.201       0.19      0.107     0.0534\n","          refrigerator       1000         16      0.258     0.0625     0.0442     0.0291\n","                remote       1000         78      0.247     0.0897     0.0935     0.0381\n","              sandwich       1000         22      0.322      0.182      0.179     0.0815\n","              scissors       1000          5          1          0          0          0\n","                 sheep       1000         61      0.266      0.492      0.351      0.112\n","                  sink       1000         11      0.395     0.0909      0.102     0.0401\n","            skateboard       1000         74      0.332      0.419      0.355      0.117\n","                  skis       1000         67      0.241      0.119     0.0808     0.0237\n","             snowboard       1000         23      0.123       0.13     0.0681     0.0181\n","                 spoon       1000         41      0.155     0.0244    0.00887    0.00443\n","           sports ball       1000         89      0.322      0.371      0.211      0.119\n","             stop sign       1000          4      0.349        0.5      0.496      0.263\n","              suitcase       1000        107      0.458     0.0467     0.0847     0.0364\n","             surfboard       1000         80      0.293      0.338      0.211     0.0726\n","            teddy bear       1000         33      0.402     0.0909     0.0789     0.0354\n","         tennis racket       1000         92       0.39      0.304      0.232      0.103\n","                   tie       1000         98      0.271      0.224      0.142     0.0444\n","               toaster       1000          1          1          0          0          0\n","                toilet       1000          9          0          0     0.0882     0.0604\n","            toothbrush       1000          8      0.658      0.125      0.173     0.0426\n","         traffic light       1000        126        0.3      0.111       0.12     0.0382\n","                 train       1000         30      0.421      0.367      0.341      0.176\n","                 truck       1000         99       0.14     0.0691     0.0577     0.0225\n","                    tv       1000         40      0.413       0.35      0.279      0.144\n","              umbrella       1000         95      0.239      0.263      0.176     0.0701\n","                  vase       1000         23       0.43      0.087     0.0879     0.0377\n","            wine glass       1000        100      0.253       0.13     0.0959     0.0352\n","                 zebra       1000          1          1          0          0          0\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}],"source":["# Download data.yaml from my github and save to your drive | after that, call your data.yaml path from your drive\n","!python train.py --img-size 640 --batch-size 32 --epochs 50 --data /content/drive/MyDrive/ObjectDetection/data.yaml --cfg models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37815,"status":"ok","timestamp":1701363252380,"user":{"displayName":"Dikha Arianda","userId":"07823774099522650036"},"user_tz":-420},"id":"y3ikmbARIzDT","outputId":"ce95803c-d49a-45a0-81a6-a3e34115d694"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/ObjectDetection/data.yaml, weights=['/content/yolov5/runs/train/exp3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v7.0-247-g3f02fde Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/ObjectDetection/Coco/val/labels.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% 1000/1000 [00:00<?, ?it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 32/32 [00:19<00:00,  1.61it/s]\n","                   all       1000       9722      0.348      0.206      0.172     0.0708\n","Speed: 0.3ms pre-process, 5.3ms inference, 5.7ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp\u001b[0m\n"]}],"source":["!python val.py --weights /content/yolov5/runs/train/exp3/weights/best.pt --data /content/drive/MyDrive/ObjectDetection/data.yaml"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMnnh5ppUukFLgwJIJGMDBv","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
